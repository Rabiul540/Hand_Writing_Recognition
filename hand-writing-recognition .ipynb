{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14229909,"sourceType":"datasetVersion","datasetId":9078137}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# train.py\n\nimport os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nimport pickle\n\nTRAIN_DIR = \"/kaggle/input/image-data/train\"\n\nPATCH_SIZE = 64\nSTRIDE = 32\nEPOCHS = 200\nBATCH_SIZE = 64\n\ndef extract_patches(img, patch_size=PATCH_SIZE, stride=STRIDE):\n    patches = []\n    h, w = img.shape\n    for y in range(0, h - patch_size, stride):\n        for x in range(0, w - patch_size, stride):\n            patch = img[y:y+patch_size, x:x+patch_size]\n            if np.mean(patch) < 245:\n                patches.append(patch)\n    return patches\n\n\nX, y = [], []\n\nfiles = [f for f in os.listdir(TRAIN_DIR)\n         if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n\nfor file in files:\n    writer_id = file[:2]\n    path = os.path.join(TRAIN_DIR, file)\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n\n    if img is None:\n        continue\n\n    img = cv2.resize(img, None, fx=0.7, fy=0.7)\n    patches = extract_patches(img)\n\n    for p in patches:\n        p = cv2.normalize(p, None, 0, 255, cv2.NORM_MINMAX)\n        p = p / 255.0\n        X.append(p)\n        y.append(writer_id)\n\nX = np.array(X, dtype=np.float32)[..., np.newaxis]\ny = np.array(y)\n\nencoder = LabelEncoder()\ny_encoded = encoder.fit_transform(y)\npickle.dump(encoder, open(\"label_encoder.pkl\", \"wb\"))\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y_encoded,\n    test_size=0.2,\n    stratify=y_encoded,\n    random_state=42\n)\n\nclass_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(y_train),\n    y=y_train\n)\nclass_weights = dict(enumerate(class_weights))\n\nnum_classes = len(np.unique(y_encoded))\n\nmodel = models.Sequential([\n    layers.Input(shape=(PATCH_SIZE, PATCH_SIZE, 1)),\n    layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\"),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D(),\n\n    layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D(),\n\n    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D(),\n\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(128, activation=\"relu\"),\n    layers.Dropout(0.5),\n    layers.Dense(num_classes, activation=\"softmax\")\n])\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-4),\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    class_weight=class_weights,\n    callbacks=[\n        callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n        callbacks.ReduceLROnPlateau(patience=4)\n    ]\n)\n\nmodel.save(\"writer_patch_level_model.keras\")\n\nprint(\" Training finished\")","metadata":{"_uuid":"81b7ee47-7e82-4ece-81ef-a5c4e031713c","_cell_guid":"15651983-5604-47e3-88bf-392fc1c249c1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-28T02:41:27.618580Z","iopub.execute_input":"2025-12-28T02:41:27.619223Z","iopub.status.idle":"2025-12-28T02:46:57.548856Z","shell.execute_reply.started":"2025-12-28T02:41:27.619195Z","shell.execute_reply":"2025-12-28T02:46:57.548239Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"2025-12-28 02:41:29.493393: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766889689.672359      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766889689.730259      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766889690.155391      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766889690.155430      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766889690.155432      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766889690.155435      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nI0000 00:00:1766889706.055811      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/200\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1766889710.915616     143 service.cc:152] XLA service 0x7e6ce4006830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1766889710.915654     143 service.cc:160]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1766889711.400540     143 cuda_dnn.cc:529] Loaded cuDNN version 91002\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 24/476\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0084 - loss: 4.6277","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1766889714.917066     143 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.0251 - loss: 4.2588 - val_accuracy: 0.0296 - val_loss: 4.1888 - learning_rate: 1.0000e-04\nEpoch 2/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.0921 - loss: 3.7155 - val_accuracy: 0.1273 - val_loss: 3.4455 - learning_rate: 1.0000e-04\nEpoch 3/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.1444 - loss: 3.2984 - val_accuracy: 0.1373 - val_loss: 3.4544 - learning_rate: 1.0000e-04\nEpoch 4/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.1959 - loss: 2.9690 - val_accuracy: 0.2986 - val_loss: 2.6998 - learning_rate: 1.0000e-04\nEpoch 5/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2344 - loss: 2.7279 - val_accuracy: 0.3299 - val_loss: 2.4693 - learning_rate: 1.0000e-04\nEpoch 6/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2814 - loss: 2.5227 - val_accuracy: 0.4350 - val_loss: 2.1579 - learning_rate: 1.0000e-04\nEpoch 7/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3138 - loss: 2.3702 - val_accuracy: 0.4396 - val_loss: 2.0081 - learning_rate: 1.0000e-04\nEpoch 8/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3523 - loss: 2.2145 - val_accuracy: 0.3604 - val_loss: 2.1400 - learning_rate: 1.0000e-04\nEpoch 9/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3790 - loss: 2.0819 - val_accuracy: 0.4704 - val_loss: 1.9090 - learning_rate: 1.0000e-04\nEpoch 10/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4120 - loss: 1.9739 - val_accuracy: 0.4413 - val_loss: 1.8877 - learning_rate: 1.0000e-04\nEpoch 11/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4347 - loss: 1.8630 - val_accuracy: 0.3135 - val_loss: 2.4088 - learning_rate: 1.0000e-04\nEpoch 12/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4661 - loss: 1.7641 - val_accuracy: 0.5766 - val_loss: 1.5143 - learning_rate: 1.0000e-04\nEpoch 13/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4921 - loss: 1.6789 - val_accuracy: 0.5480 - val_loss: 1.5936 - learning_rate: 1.0000e-04\nEpoch 14/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5173 - loss: 1.5946 - val_accuracy: 0.5919 - val_loss: 1.4844 - learning_rate: 1.0000e-04\nEpoch 15/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5359 - loss: 1.5144 - val_accuracy: 0.6110 - val_loss: 1.3774 - learning_rate: 1.0000e-04\nEpoch 16/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5577 - loss: 1.4472 - val_accuracy: 0.6038 - val_loss: 1.4363 - learning_rate: 1.0000e-04\nEpoch 17/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5807 - loss: 1.3783 - val_accuracy: 0.5770 - val_loss: 1.5556 - learning_rate: 1.0000e-04\nEpoch 18/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5954 - loss: 1.3125 - val_accuracy: 0.6177 - val_loss: 1.3196 - learning_rate: 1.0000e-04\nEpoch 19/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6207 - loss: 1.2368 - val_accuracy: 0.6150 - val_loss: 1.4086 - learning_rate: 1.0000e-04\nEpoch 20/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6363 - loss: 1.1960 - val_accuracy: 0.5305 - val_loss: 1.5350 - learning_rate: 1.0000e-04\nEpoch 21/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6478 - loss: 1.1365 - val_accuracy: 0.6582 - val_loss: 1.1247 - learning_rate: 1.0000e-04\nEpoch 22/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6562 - loss: 1.1043 - val_accuracy: 0.6631 - val_loss: 1.2097 - learning_rate: 1.0000e-04\nEpoch 23/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6797 - loss: 1.0487 - val_accuracy: 0.5674 - val_loss: 1.4470 - learning_rate: 1.0000e-04\nEpoch 24/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6953 - loss: 1.0051 - val_accuracy: 0.5160 - val_loss: 1.6476 - learning_rate: 1.0000e-04\nEpoch 25/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7010 - loss: 0.9629 - val_accuracy: 0.5479 - val_loss: 1.5875 - learning_rate: 1.0000e-04\nEpoch 26/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7179 - loss: 0.9190 - val_accuracy: 0.7851 - val_loss: 0.8264 - learning_rate: 1.0000e-05\nEpoch 27/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7300 - loss: 0.8835 - val_accuracy: 0.7866 - val_loss: 0.8230 - learning_rate: 1.0000e-05\nEpoch 28/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7303 - loss: 0.8831 - val_accuracy: 0.7886 - val_loss: 0.8143 - learning_rate: 1.0000e-05\nEpoch 29/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7334 - loss: 0.8709 - val_accuracy: 0.7864 - val_loss: 0.8075 - learning_rate: 1.0000e-05\nEpoch 30/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7348 - loss: 0.8750 - val_accuracy: 0.7924 - val_loss: 0.8098 - learning_rate: 1.0000e-05\nEpoch 31/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7357 - loss: 0.8696 - val_accuracy: 0.7870 - val_loss: 0.8247 - learning_rate: 1.0000e-05\nEpoch 32/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7335 - loss: 0.8706 - val_accuracy: 0.7919 - val_loss: 0.7971 - learning_rate: 1.0000e-05\nEpoch 33/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7420 - loss: 0.8490 - val_accuracy: 0.7931 - val_loss: 0.8006 - learning_rate: 1.0000e-05\nEpoch 34/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7346 - loss: 0.8594 - val_accuracy: 0.7908 - val_loss: 0.7853 - learning_rate: 1.0000e-05\nEpoch 35/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7422 - loss: 0.8538 - val_accuracy: 0.7907 - val_loss: 0.8096 - learning_rate: 1.0000e-05\nEpoch 36/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7459 - loss: 0.8415 - val_accuracy: 0.7866 - val_loss: 0.7916 - learning_rate: 1.0000e-05\nEpoch 37/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7447 - loss: 0.8417 - val_accuracy: 0.7893 - val_loss: 0.7798 - learning_rate: 1.0000e-05\nEpoch 38/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7479 - loss: 0.8273 - val_accuracy: 0.7976 - val_loss: 0.7787 - learning_rate: 1.0000e-05\nEpoch 39/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7508 - loss: 0.8197 - val_accuracy: 0.7864 - val_loss: 0.7839 - learning_rate: 1.0000e-05\nEpoch 40/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7505 - loss: 0.8203 - val_accuracy: 0.7919 - val_loss: 0.7838 - learning_rate: 1.0000e-05\nEpoch 41/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7526 - loss: 0.8195 - val_accuracy: 0.7982 - val_loss: 0.7901 - learning_rate: 1.0000e-05\nEpoch 42/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7466 - loss: 0.8279 - val_accuracy: 0.7940 - val_loss: 0.7650 - learning_rate: 1.0000e-05\nEpoch 43/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7508 - loss: 0.8182 - val_accuracy: 0.8014 - val_loss: 0.7620 - learning_rate: 1.0000e-05\nEpoch 44/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7509 - loss: 0.8143 - val_accuracy: 0.7990 - val_loss: 0.7726 - learning_rate: 1.0000e-05\nEpoch 45/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7544 - loss: 0.8148 - val_accuracy: 0.7958 - val_loss: 0.7735 - learning_rate: 1.0000e-05\nEpoch 46/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7550 - loss: 0.8045 - val_accuracy: 0.8012 - val_loss: 0.7581 - learning_rate: 1.0000e-05\nEpoch 47/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7528 - loss: 0.8153 - val_accuracy: 0.7937 - val_loss: 0.7572 - learning_rate: 1.0000e-05\nEpoch 48/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7603 - loss: 0.7947 - val_accuracy: 0.8031 - val_loss: 0.7519 - learning_rate: 1.0000e-05\nEpoch 49/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7561 - loss: 0.8051 - val_accuracy: 0.8014 - val_loss: 0.7644 - learning_rate: 1.0000e-05\nEpoch 50/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7593 - loss: 0.7890 - val_accuracy: 0.8029 - val_loss: 0.7489 - learning_rate: 1.0000e-05\nEpoch 51/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7644 - loss: 0.7726 - val_accuracy: 0.8001 - val_loss: 0.7589 - learning_rate: 1.0000e-05\nEpoch 52/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7619 - loss: 0.7826 - val_accuracy: 0.8057 - val_loss: 0.7414 - learning_rate: 1.0000e-05\nEpoch 53/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7663 - loss: 0.7659 - val_accuracy: 0.8061 - val_loss: 0.7464 - learning_rate: 1.0000e-05\nEpoch 54/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7633 - loss: 0.7751 - val_accuracy: 0.8036 - val_loss: 0.7554 - learning_rate: 1.0000e-05\nEpoch 55/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7699 - loss: 0.7628 - val_accuracy: 0.8073 - val_loss: 0.7456 - learning_rate: 1.0000e-05\nEpoch 56/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7716 - loss: 0.7661 - val_accuracy: 0.8098 - val_loss: 0.7346 - learning_rate: 1.0000e-05\nEpoch 57/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7673 - loss: 0.7592 - val_accuracy: 0.8040 - val_loss: 0.7275 - learning_rate: 1.0000e-05\nEpoch 58/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7692 - loss: 0.7566 - val_accuracy: 0.8069 - val_loss: 0.7278 - learning_rate: 1.0000e-05\nEpoch 59/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7707 - loss: 0.7546 - val_accuracy: 0.8083 - val_loss: 0.7318 - learning_rate: 1.0000e-05\nEpoch 60/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7752 - loss: 0.7426 - val_accuracy: 0.8020 - val_loss: 0.7272 - learning_rate: 1.0000e-05\nEpoch 61/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7686 - loss: 0.7503 - val_accuracy: 0.8135 - val_loss: 0.7422 - learning_rate: 1.0000e-05\nEpoch 62/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7760 - loss: 0.7355 - val_accuracy: 0.8127 - val_loss: 0.7098 - learning_rate: 1.0000e-05\nEpoch 63/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7806 - loss: 0.7345 - val_accuracy: 0.8108 - val_loss: 0.7316 - learning_rate: 1.0000e-05\nEpoch 64/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7759 - loss: 0.7312 - val_accuracy: 0.8052 - val_loss: 0.7115 - learning_rate: 1.0000e-05\nEpoch 65/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7813 - loss: 0.7319 - val_accuracy: 0.8139 - val_loss: 0.7168 - learning_rate: 1.0000e-05\nEpoch 66/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7786 - loss: 0.7347 - val_accuracy: 0.8052 - val_loss: 0.7281 - learning_rate: 1.0000e-05\nEpoch 67/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7824 - loss: 0.7214 - val_accuracy: 0.8140 - val_loss: 0.7053 - learning_rate: 1.0000e-06\nEpoch 68/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7832 - loss: 0.7197 - val_accuracy: 0.8152 - val_loss: 0.7059 - learning_rate: 1.0000e-06\nEpoch 69/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7811 - loss: 0.7250 - val_accuracy: 0.8143 - val_loss: 0.7043 - learning_rate: 1.0000e-06\nEpoch 70/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7819 - loss: 0.7274 - val_accuracy: 0.8161 - val_loss: 0.7062 - learning_rate: 1.0000e-06\nEpoch 71/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7811 - loss: 0.7209 - val_accuracy: 0.8147 - val_loss: 0.7022 - learning_rate: 1.0000e-06\nEpoch 72/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7868 - loss: 0.7148 - val_accuracy: 0.8156 - val_loss: 0.7025 - learning_rate: 1.0000e-06\nEpoch 73/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7850 - loss: 0.7228 - val_accuracy: 0.8153 - val_loss: 0.7039 - learning_rate: 1.0000e-06\nEpoch 74/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7843 - loss: 0.7197 - val_accuracy: 0.8154 - val_loss: 0.7022 - learning_rate: 1.0000e-06\nEpoch 75/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7813 - loss: 0.7238 - val_accuracy: 0.8158 - val_loss: 0.7028 - learning_rate: 1.0000e-06\nEpoch 76/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7858 - loss: 0.7141 - val_accuracy: 0.8152 - val_loss: 0.7025 - learning_rate: 1.0000e-07\nEpoch 77/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7866 - loss: 0.7132 - val_accuracy: 0.8157 - val_loss: 0.7031 - learning_rate: 1.0000e-07\nEpoch 78/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7824 - loss: 0.7131 - val_accuracy: 0.8157 - val_loss: 0.7022 - learning_rate: 1.0000e-07\nEpoch 79/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7831 - loss: 0.7216 - val_accuracy: 0.8156 - val_loss: 0.7034 - learning_rate: 1.0000e-07\nEpoch 80/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7897 - loss: 0.7091 - val_accuracy: 0.8148 - val_loss: 0.7027 - learning_rate: 1.0000e-08\nEpoch 81/200\n\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7839 - loss: 0.7133 - val_accuracy: 0.8154 - val_loss: 0.7029 - learning_rate: 1.0000e-08\n Training finished\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#test.py\nimport os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom collections import Counter\nimport pickle\nimport csv\n\n# =========================\n# Configuration (MUST MATCH TRAINING)\n# =========================\nTEST_DIR = \"/kaggle/input/image-data/test\"\n\nPATCH_SIZE = 64\nSTRIDE = 32\n\nMODEL_PATH = \"writer_patch_level_model.keras\"\nOUTPUT_CSV = \"test_predictions.csv\"\n\n# =========================\n# Load Model & Encoder\n# =========================\nmodel = tf.keras.models.load_model(MODEL_PATH)\nencoder = pickle.load(open(\"label_encoder.pkl\", \"rb\"))\n\n# =========================\n# Patch Extraction (SAME AS TRAINING)\n# =========================\ndef extract_patches(img, patch_size=PATCH_SIZE, stride=STRIDE):\n    patches = []\n    h, w = img.shape\n\n    for y in range(0, h - patch_size, stride):\n        for x in range(0, w - patch_size, stride):\n            patch = img[y:y+patch_size, x:x+patch_size]\n\n            # skip mostly white patches\n            if np.mean(patch) < 245:\n                patches.append(patch)\n\n    return patches\n\n# =========================\n# Evaluation + CSV Logging\n# =========================\ncorrect = 0\ntotal = 0\nrows = []\n\nprint(\"Evaluating test data ...\")\n\ntest_files = [\n    f for f in os.listdir(TEST_DIR)\n    if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n]\n\nfor file in test_files:\n    true_writer = file[:2]   # SAME logic as training\n    path = os.path.join(TEST_DIR, file)\n\n    final_prediction = \"\"\n    num_patches = 0\n    status = \"ok\"\n\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    if img is None:\n        status = \"skipped_image_read_failed\"\n        rows.append([file, true_writer, final_prediction, num_patches, \"\", status])\n        continue\n\n    # Optional resize (same as training)\n    img = cv2.resize(img, None, fx=0.7, fy=0.7)\n\n    patches = extract_patches(img)\n    num_patches = len(patches)\n\n    if num_patches == 0:\n        status = \"skipped_no_patches\"\n        rows.append([file, true_writer, final_prediction, num_patches, \"\", status])\n        continue\n\n    X = []\n    for p in patches:\n        p = cv2.normalize(p, None, 0, 255, cv2.NORM_MINMAX)\n        p = p / 255.0\n        X.append(p)\n\n    X = np.array(X, dtype=np.float32)[..., np.newaxis]\n\n    # Predict patches\n    preds = model.predict(X, verbose=0)\n    pred_classes = np.argmax(preds, axis=1)\n    pred_labels = encoder.inverse_transform(pred_classes)\n\n    # Majority vote (page-level)\n    final_prediction = Counter(pred_labels).most_common(1)[0][0]\n\n    total += 1\n    is_correct = int(final_prediction == true_writer)\n    correct += is_correct\n\n    print(f\"{file} → True: {true_writer}, Predicted: {final_prediction}\")\n\n    rows.append([\n        file,\n        true_writer,\n        final_prediction\n    ])\n\n# =========================\n# Accuracy + Save CSV\n# =========================\naccuracy = (correct / total) * 100 if total > 0 else 0\n\nprint(\"\\nTest Accuracy (page-level): {:.2f}%\".format(accuracy))\nprint(f\"Correct: {correct} / Total: {total}\")\n\nwith open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n    writer = csv.writer(f)\n    writer.writerow([\n        \"filename\",\n        \"true_writer\",\n        \"predicted_writer\"\n    ])\n    writer.writerows(rows)\n    writer.writerow([])\n    writer.writerow([\"SUMMARY\", \"\", \"\", \"\", \"\", \"\"])\n    writer.writerow([\"accuracy_percent\", accuracy, \"correct\", correct, \"total\", total])\n\nprint(f\"\\nSaved results to: {OUTPUT_CSV}\")","metadata":{"_uuid":"c6a67fc9-2a5e-45d4-92ee-f58d8d36f863","_cell_guid":"ae0e28b3-51c7-4d25-9152-f63cc3139e47","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-28T03:31:57.410020Z","iopub.execute_input":"2025-12-28T03:31:57.410561Z","iopub.status.idle":"2025-12-28T03:32:17.848518Z","shell.execute_reply.started":"2025-12-28T03:31:57.410528Z","shell.execute_reply":"2025-12-28T03:32:17.847862Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Evaluating test data ...\n10_2_290.png → True: 10, Predicted: 10\n04_2_494.png → True: 04, Predicted: 04\n01_2_491.png → True: 01, Predicted: 01\n66_2_556.png → True: 66, Predicted: 66\n57_2_337.png → True: 57, Predicted: 57\n42_2_392.png → True: 42, Predicted: 42\n54_2_334.png → True: 54, Predicted: 54\n43_2_323.png → True: 43, Predicted: 43\n20_2_300.png → True: 20, Predicted: 20\n22_2_372.png → True: 22, Predicted: 22\n55_2_335.png → True: 55, Predicted: 55\n62_2_342.png → True: 62, Predicted: 62\n51_2_401.png → True: 51, Predicted: 11\n53_2_543.png → True: 53, Predicted: 68\n50_2_330.png → True: 50, Predicted: 50\n06_2_496.png → True: 06, Predicted: 06\n04_2_424.png → True: 04, Predicted: 04\n07_2_287.png → True: 07, Predicted: 07\n24_2_304.png → True: 24, Predicted: 24\n70_2_420.png → True: 70, Predicted: 70\n46_2_466.png → True: 46, Predicted: 46\n60_2_480.png → True: 60, Predicted: 60\n41_2_321.png → True: 41, Predicted: 41\n39_2_529.png → True: 39, Predicted: 39\n18_2_508.png → True: 18, Predicted: 43\n19_2_299.png → True: 19, Predicted: 19\n37_2_457.png → True: 37, Predicted: 37\n49_2_329.png → True: 49, Predicted: 49\n19_2_369.png → True: 19, Predicted: 19\n42_2_532.png → True: 42, Predicted: 42\n13_2_433.png → True: 13, Predicted: 23\n45_2_325.png → True: 45, Predicted: 45\n06_2_286.png → True: 06, Predicted: 06\n07_2_427.png → True: 07, Predicted: 07\n57_2_407.png → True: 57, Predicted: 57\n23_2_303.png → True: 23, Predicted: 23\n70_2_490.png → True: 70, Predicted: 70\n16_2_506.png → True: 16, Predicted: 16\n55_2_405.png → True: 55, Predicted: 55\n44_2_464.png → True: 44, Predicted: 44\n34_2_524.png → True: 34, Predicted: 34\n21_2_301.png → True: 21, Predicted: 21\n28_2_518.png → True: 28, Predicted: 28\n33_2_523.png → True: 33, Predicted: 33\n54_2_404.png → True: 54, Predicted: 54\n62_2_552.png → True: 62, Predicted: 62\n48_2_328.png → True: 48, Predicted: 48\n68_2_558.png → True: 68, Predicted: 68\n44_2_324.png → True: 44, Predicted: 44\n30_2_310.png → True: 30, Predicted: 30\n67_2_557.png → True: 67, Predicted: 55\n69_2_559.png → True: 69, Predicted: 69\n15_2_435.png → True: 15, Predicted: 15\n22_2_302.png → True: 22, Predicted: 22\n31_2_381.png → True: 31, Predicted: 31\n60_2_340.png → True: 60, Predicted: 60\n08_2_358.png → True: 08, Predicted: 08\n45_2_395.png → True: 45, Predicted: 45\n11_2_361.png → True: 11, Predicted: 49\n31_2_311.png → True: 31, Predicted: 31\n67_2_487.png → True: 67, Predicted: 55\n26_2_306.png → True: 26, Predicted: 17\n25_2_305.png → True: 25, Predicted: 25\n50_2_470.png → True: 50, Predicted: 50\n03_2_493.png → True: 03, Predicted: 03\n36_2_386.png → True: 36, Predicted: 36\n35_2_385.png → True: 35, Predicted: 35\n11_2_431.png → True: 11, Predicted: 11\n64_2_414.png → True: 64, Predicted: 64\n14_2_434.png → True: 14, Predicted: 14\n40_2_460.png → True: 40, Predicted: 01\n43_2_393.png → True: 43, Predicted: 43\n58_2_548.png → True: 58, Predicted: 58\n05_2_355.png → True: 05, Predicted: 05\n64_2_554.png → True: 64, Predicted: 64\n13_2_293.png → True: 13, Predicted: 23\n10_2_360.png → True: 10, Predicted: 10\n16_2_436.png → True: 16, Predicted: 16\n65_2_345.png → True: 65, Predicted: 65\n17_2_297.png → True: 17, Predicted: 17\n02_2_352.png → True: 02, Predicted: 26\n20_2_440.png → True: 20, Predicted: 20\n08_2_428.png → True: 08, Predicted: 08\n01_2_281.png → True: 01, Predicted: 01\n35_2_315.png → True: 35, Predicted: 35\n25_2_375.png → True: 25, Predicted: 25\n09_2_359.png → True: 09, Predicted: 09\n52_2_332.png → True: 52, Predicted: 52\n52_2_472.png → True: 52, Predicted: 52\n36_2_316.png → True: 36, Predicted: 36\n53_2_403.png → True: 53, Predicted: 53\n29_2_519.png → True: 29, Predicted: 29\n21_2_371.png → True: 21, Predicted: 21\n15_2_295.png → True: 15, Predicted: 15\n23_2_373.png → True: 23, Predicted: 23\n61_2_551.png → True: 61, Predicted: 61\n47_2_397.png → True: 47, Predicted: 37\n66_2_486.png → True: 66, Predicted: 66\n37_2_387.png → True: 37, Predicted: 37\n69_2_349.png → True: 69, Predicted: 69\n32_2_382.png → True: 32, Predicted: 32\n14_2_504.png → True: 14, Predicted: 14\n40_2_390.png → True: 40, Predicted: 01\n29_2_309.png → True: 29, Predicted: 29\n24_2_514.png → True: 24, Predicted: 24\n49_2_539.png → True: 49, Predicted: 49\n33_2_383.png → True: 33, Predicted: 27\n17_2_507.png → True: 17, Predicted: 17\n28_2_378.png → True: 28, Predicted: 28\n63_2_413.png → True: 63, Predicted: 63\n63_2_553.png → True: 63, Predicted: 63\n38_2_388.png → True: 38, Predicted: 38\n65_2_485.png → True: 65, Predicted: 65\n38_2_318.png → True: 38, Predicted: 38\n39_2_319.png → True: 39, Predicted: 39\n03_2_353.png → True: 03, Predicted: 03\n41_2_531.png → True: 41, Predicted: 41\n27_2_447.png → True: 27, Predicted: 27\n12_2_432.png → True: 12, Predicted: 12\n34_2_314.png → True: 34, Predicted: 34\n27_2_377.png → True: 27, Predicted: 27\n68_2_418.png → True: 68, Predicted: 68\n48_2_468.png → True: 48, Predicted: 48\n32_2_452.png → True: 32, Predicted: 32\n26_2_516.png → True: 26, Predicted: 26\n51_2_471.png → True: 51, Predicted: 51\n59_2_339.png → True: 59, Predicted: 59\n58_2_408.png → True: 58, Predicted: 58\n47_2_537.png → True: 47, Predicted: 37\n56_2_476.png → True: 56, Predicted: 16\n61_2_481.png → True: 61, Predicted: 61\n30_2_520.png → True: 30, Predicted: 30\n59_2_409.png → True: 59, Predicted: 59\n56_2_546.png → True: 56, Predicted: 39\n46_2_326.png → True: 46, Predicted: 32\n18_2_368.png → True: 18, Predicted: 43\n09_2_289.png → True: 09, Predicted: 09\n12_2_362.png → True: 12, Predicted: 12\n02_2_492.png → True: 02, Predicted: 26\n05_2_495.png → True: 05, Predicted: 05\n\nTest Accuracy (page-level): 85.71%\nCorrect: 120 / Total: 140\n\nSaved results to: test_predictions.csv\n","output_type":"stream"}],"execution_count":3}]}